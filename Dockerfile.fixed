# Dockerfile corrigido com suporte GPU completo
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# VariÃ¡veis de ambiente
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    CUDA_VISIBLE_DEVICES=0 \
    HF_HOME=/app/models \
    TRANSFORMERS_CACHE=/app/models \
    SENTENCE_TRANSFORMERS_HOME=/app/models \
    USE_GPU=true

# Instalar Python 3.11 e dependÃªncias
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    python3.11-distutils \
    git \
    curl \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/* \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# Atualizar pip e instalar PyTorch com CUDA
RUN python3.11 -m pip install --upgrade pip setuptools wheel && \
    python3.11 -m pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121

# Instalar dependÃªncias com versÃµes compatÃ­veis
RUN python3.11 -m pip install --no-cache-dir \
    transformers==4.36.2 \
    sentence-transformers==2.2.2 \
    huggingface-hub==0.19.4 \
    qdrant-client==1.7.0 \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    pydantic==2.5.0 \
    numpy==1.24.3 \
    scikit-learn==1.3.2 \
    python-multipart==0.0.6 \
    httpx==0.25.1 \
    python-jose[cryptography]==3.3.0 \
    passlib[bcrypt]==1.7.4 \
    aiofiles==23.2.1 \
    accelerate==0.25.0 \
    structlog==23.2.0 \
    uvloop==0.19.0

# Copiar cÃ³digo
COPY app/ /app/app/

# Criar diretÃ³rios
RUN mkdir -p /app/data /app/models

# Script de inicializaÃ§Ã£o corrigido
RUN cat > /app/start.sh << 'EOF'
#!/bin/bash
echo "ğŸš€ Iniciando com suporte GPU..."
echo "ğŸ“Š Verificando GPU disponÃ­vel:"
python3.11 -c "import torch; print(f'CUDA disponÃ­vel: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NÃ£o detectada\"}')"
echo "ğŸ“¦ Verificando modelos..."
python3.11 -c "
try:
    from sentence_transformers import SentenceTransformer
    print('âœ“ Sentence Transformers OK')
    model = SentenceTransformer('intfloat/multilingual-e5-large')
    print('âœ“ Dense model carregado')
except Exception as e:
    print(f'âš ï¸ Erro ao carregar dense model: {e}')
"
python3.11 -c "
try:
    from transformers import AutoTokenizer, AutoModelForMaskedLM
    print('âœ“ Transformers OK')
    tokenizer = AutoTokenizer.from_pretrained('prithivida/Splade_PP_en_v1')
    model = AutoModelForMaskedLM.from_pretrained('prithivida/Splade_PP_en_v1')
    print('âœ“ Sparse model carregado')
except Exception as e:
    print(f'âš ï¸ Erro ao carregar sparse model: {e}')
"
echo "âœ… Sistema pronto! Iniciando API..."
exec python3.11 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1
EOF

RUN chmod +x /app/start.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=180s --retries=5 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["/app/start.sh"]