# Dockerfile compatÃ­vel com CUDA 11.8 (Easypanel)
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# VariÃ¡veis de ambiente
ENV NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    CUDA_VISIBLE_DEVICES=0 \
    DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    HF_HOME=/app/models \
    TRANSFORMERS_CACHE=/app/models \
    SENTENCE_TRANSFORMERS_HOME=/app/models \
    USE_GPU=true

# Instalar Python 3.11
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    python3.11-distutils \
    git \
    curl \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/* \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \
    && update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1

WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# IMPORTANTE: Instalar PyTorch para CUDA 11.8
RUN python3.11 -m pip install --upgrade pip setuptools wheel && \
    python3.11 -m pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118

# Instalar outras dependÃªncias
RUN python3.11 -m pip install --no-cache-dir \
    transformers==4.36.2 \
    sentence-transformers==2.2.2 \
    huggingface-hub==0.19.4 \
    qdrant-client==1.7.0 \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    pydantic==2.5.0 \
    pydantic-settings==2.1.0 \
    numpy==1.24.3 \
    scikit-learn==1.3.2 \
    python-multipart==0.0.6 \
    httpx==0.25.1 \
    python-jose[cryptography]==3.3.0 \
    passlib[bcrypt]==1.7.4 \
    aiofiles==23.2.1 \
    accelerate==0.25.0 \
    structlog==23.2.0 \
    uvloop==0.19.0 \
    scipy==1.11.4 \
    pillow==10.1.0 \
    nvidia-ml-py3

# Copiar cÃ³digo
COPY app/ /app/app/

# Criar diretÃ³rios
RUN mkdir -p /app/data /app/models

# Script de inicializaÃ§Ã£o
RUN cat > /app/start.sh << 'EOF'
#!/bin/bash
echo "==========================================="
echo "ðŸš€ Iniciando com CUDA 11.8 (compatÃ­vel com Easypanel)"
echo "==========================================="

# Verificar GPU
echo "ðŸ“Š Verificando GPU..."
python3.11 -c "
import torch
import os

print(f'PyTorch: {torch.__version__}')
print(f'CUDA compilado: {torch.version.cuda}')
print(f'CUDA disponÃ­vel: {torch.cuda.is_available()}')

if torch.cuda.is_available():
    print(f'âœ… GPU detectada: {torch.cuda.get_device_name(0)}')
    print(f'âœ… MemÃ³ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
    os.environ['USE_GPU'] = 'true'
else:
    print('âš ï¸ GPU nÃ£o disponÃ­vel - usando CPU')
    os.environ['USE_GPU'] = 'false'
"

# Testar nvidia-ml-py
python3.11 -c "
try:
    import pynvml
    pynvml.nvmlInit()
    count = pynvml.nvmlDeviceGetCount()
    print(f'âœ… nvidia-ml-py: {count} GPU(s) detectada(s)')
except:
    print('âš ï¸ nvidia-ml-py: GPU nÃ£o acessÃ­vel')
" 2>/dev/null

echo ""
echo "ðŸ“¦ Carregando modelos..."

# Carregar modelos
python3.11 -c "
from sentence_transformers import SentenceTransformer
print('Carregando modelo denso...')
model = SentenceTransformer('intfloat/multilingual-e5-large')
print('âœ… Modelo denso carregado')

from transformers import AutoTokenizer, AutoModelForMaskedLM
print('Carregando modelo esparso...')
tokenizer = AutoTokenizer.from_pretrained('prithivida/Splade_PP_en_v1')
model = AutoModelForMaskedLM.from_pretrained('prithivida/Splade_PP_en_v1')
print('âœ… Modelo esparso carregado')
"

echo ""
echo "âœ… Iniciando API..."
echo "==========================================="

# Iniciar API
exec python3.11 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1
EOF

RUN chmod +x /app/start.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=180s --retries=5 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["/app/start.sh"]