# Dockerfile ESPECIAL para Easypanel com GPU FOR√áADA
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# FOR√áAR detec√ß√£o de GPU
ENV NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    CUDA_VISIBLE_DEVICES=0 \
    FORCE_CUDA=1 \
    CUDA_LAUNCH_BLOCKING=0 \
    DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    HF_HOME=/app/models \
    TRANSFORMERS_CACHE=/app/models \
    SENTENCE_TRANSFORMERS_HOME=/app/models \
    USE_GPU=true

# Instalar Python 3.11 e depend√™ncias
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    python3.11-distutils \
    git \
    curl \
    gcc \
    g++ \
    # Ferramentas NVIDIA
    nvidia-utils-520 \
    && rm -rf /var/lib/apt/lists/* \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \
    && update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1

WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# Instalar PyTorch com CUDA FOR√áADO
RUN python3.11 -m pip install --upgrade pip setuptools wheel && \
    python3.11 -m pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 --index-url https://download.pytorch.org/whl/cu121 && \
    python3.11 -m pip install nvidia-ml-py3

# Instalar todas as depend√™ncias
RUN python3.11 -m pip install --no-cache-dir \
    transformers==4.36.2 \
    sentence-transformers==2.2.2 \
    huggingface-hub==0.19.4 \
    qdrant-client==1.7.0 \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    pydantic==2.5.0 \
    pydantic-settings==2.1.0 \
    numpy==1.24.3 \
    scikit-learn==1.3.2 \
    python-multipart==0.0.6 \
    httpx==0.25.1 \
    python-jose[cryptography]==3.3.0 \
    passlib[bcrypt]==1.7.4 \
    aiofiles==23.2.1 \
    accelerate==0.25.0 \
    structlog==23.2.0 \
    uvloop==0.19.0 \
    scipy==1.11.4 \
    pillow==10.1.0

# Copiar c√≥digo
COPY app/ /app/app/

# Criar diret√≥rios
RUN mkdir -p /app/data /app/models

# Script que FOR√áA uso de GPU
RUN cat > /app/start.sh << 'EOF'
#!/bin/bash
echo "==========================================="
echo "üöÄ FOR√áANDO DETEC√á√ÉO DE GPU NO EASYPANEL"
echo "==========================================="

# Tentar detectar GPU de v√°rias formas
echo "üîç M√©todo 1: nvidia-smi"
nvidia-smi 2>/dev/null && echo "‚úÖ nvidia-smi detectou GPU" || echo "‚ùå nvidia-smi falhou"

echo ""
echo "üîç M√©todo 2: Verifica√ß√£o Python com CUDA for√ßado"
python3.11 -c "
import os
import sys

# For√ßar vari√°veis de ambiente
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['USE_GPU'] = 'true'
os.environ['FORCE_CUDA'] = '1'

print('Vari√°veis de ambiente configuradas:')
print(f'  CUDA_VISIBLE_DEVICES: {os.environ.get(\"CUDA_VISIBLE_DEVICES\")}')
print(f'  NVIDIA_VISIBLE_DEVICES: {os.environ.get(\"NVIDIA_VISIBLE_DEVICES\")}')
print(f'  USE_GPU: {os.environ.get(\"USE_GPU\")}')
print('')

try:
    import torch
    print(f'üîß PyTorch version: {torch.__version__}')
    print(f'üîß CUDA compiled: {torch.version.cuda}')
    
    # Tentar for√ßar CUDA
    if not torch.cuda.is_available():
        print('‚ö†Ô∏è CUDA n√£o dispon√≠vel diretamente')
        print('üîß Tentando for√ßar inicializa√ß√£o CUDA...')
        
        # Tentar diferentes m√©todos
        try:
            torch.cuda.init()
            print('‚úÖ CUDA init executado')
        except:
            print('‚ùå CUDA init falhou')
        
        # Verificar novamente
        if torch.cuda.is_available():
            print('‚úÖ CUDA agora dispon√≠vel!')
        else:
            print('‚ö†Ô∏è CUDA ainda n√£o dispon√≠vel')
            print('üìù Nota: No Easypanel, pode ser necess√°rio:')
            print('   1. Adicionar runtime: nvidia no docker-compose')
            print('   2. Ou mapear devices: /dev/nvidia*')
    else:
        print(f'‚úÖ CUDA dispon√≠vel!')
        print(f'‚úÖ GPU: {torch.cuda.get_device_name(0)}')
        print(f'‚úÖ Mem√≥ria: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
        
except Exception as e:
    print(f'‚ùå Erro: {e}')
"

echo ""
echo "üîç M√©todo 3: nvidia-ml-py"
python3.11 -c "
try:
    import pynvml
    pynvml.nvmlInit()
    device_count = pynvml.nvmlDeviceGetCount()
    print(f'‚úÖ nvidia-ml-py detectou {device_count} GPU(s)')
    for i in range(device_count):
        handle = pynvml.nvmlDeviceGetHandleByIndex(i)
        name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')
        print(f'   GPU {i}: {name}')
except Exception as e:
    print(f'‚ùå nvidia-ml-py falhou: {e}')
"

echo ""
echo "==========================================="
echo "üì¶ Carregando modelos..."
echo "==========================================="

# For√ßar USE_GPU=true sempre
export USE_GPU=true
export CUDA_VISIBLE_DEVICES=0
export FORCE_CUDA=1

python3.11 -c "
import os
os.environ['USE_GPU'] = 'true'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

try:
    print('üì• Carregando modelo denso...')
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer('intfloat/multilingual-e5-large', device='cuda:0' if os.environ.get('USE_GPU') == 'true' else 'cpu')
    print('‚úÖ Modelo denso carregado')
except Exception as e:
    print(f'‚ö†Ô∏è Modelo denso: {e}')

try:
    print('üì• Carregando modelo esparso...')
    from transformers import AutoTokenizer, AutoModelForMaskedLM
    tokenizer = AutoTokenizer.from_pretrained('prithivida/Splade_PP_en_v1')
    model = AutoModelForMaskedLM.from_pretrained('prithivida/Splade_PP_en_v1')
    print('‚úÖ Modelo esparso carregado')
except Exception as e:
    print(f'‚ö†Ô∏è Modelo esparso: {e}')
"

echo ""
echo "==========================================="
echo "‚úÖ Iniciando API com GPU FOR√áADA..."
echo "==========================================="

# Iniciar com vari√°veis for√ßadas
export USE_GPU=true
export CUDA_VISIBLE_DEVICES=0
export FORCE_CUDA=1

exec python3.11 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1
EOF

RUN chmod +x /app/start.sh

# Verificar GPU na build (opcional)
RUN python3.11 -c "import torch; print(f'Build time - CUDA: {torch.version.cuda}')" || true

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=180s --retries=5 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["/app/start.sh"]